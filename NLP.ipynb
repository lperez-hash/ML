{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "mpl.rcParams['figure.dpi'] = 105\n",
    "mpl.rcParams['figure.figsize'] = (7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set noticias\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data_20_news = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parte 2: Pipelines y Gridsearch\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data_20_news = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 11314\n",
      "\n",
      "Estratificacion:\n",
      "Clase:0, alt.atheism                 480\n",
      "Clase:1, comp.graphics               584\n",
      "Clase:2, comp.os.ms-windows.misc     591\n",
      "Clase:3, comp.sys.ibm.pc.hardware    590\n",
      "Clase:4, comp.sys.mac.hardware       578\n",
      "Clase:5, comp.windows.x              593\n",
      "Clase:6, misc.forsale                585\n",
      "Clase:7, rec.autos                   594\n",
      "Clase:8, rec.motorcycles             598\n",
      "Clase:9, rec.sport.baseball          597\n",
      "Clase:10, rec.sport.hockey           600\n",
      "Clase:11, sci.crypt                  595\n",
      "Clase:12, sci.electronics            591\n",
      "Clase:13, sci.med                    594\n",
      "Clase:14, sci.space                  593\n",
      "Clase:15, soc.religion.christian     599\n",
      "Clase:16, talk.politics.guns         546\n",
      "Clase:17, talk.politics.mideast      564\n",
      "Clase:18, talk.politics.misc         465\n",
      "Clase:19, talk.religion.misc         377\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Samples: {len(data_20_news.data)}\")\n",
    "#print(f\"Clases: {data_20_news.target_names}\")\n",
    "dictAx = {index: f\"Clase:{index}, {feature}\" for index, feature in enumerate(data_20_news.target_names)}\n",
    "print(f\"\\nEstratificacion:\\n{pd.Series(data_20_news.target).value_counts().sort_index().rename(index=dictAx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857 documentos y 2 categorías.\n"
     ]
    }
   ],
   "source": [
    "# Se trabajará sólo con 2 categorias: 'alt.atheism', 'talk.religion.misc'\n",
    "#Test\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc']\n",
    "text_data = fetch_20newsgroups(subset ='train', \n",
    "                          categories = categories)\n",
    "\n",
    "print(f\"{len(text_data.filenames)} documentos y {len(text_data.target_names)} categorías.\")\n",
    "X_train = text_data.data\n",
    "y_train = text_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570 documentos y 2 categorías.\n"
     ]
    }
   ],
   "source": [
    "# Realizamos el mismo proceso para los datos de prueba.\n",
    "text_data_test = fetch_20newsgroups(subset ='test', categories = categories)\n",
    "\n",
    "print(f\"{len(text_data_test.filenames)} documentos y {len(text_data_test.target_names)} categorías.\")\n",
    "\n",
    "X_test = text_data_test.data\n",
    "y_test = text_data_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: V2110A@VM.TEMPLE.EDU (Richard Hoenes)\n",
      "Subject: Re: A Message for you Mr. President: How do you know what happened?\n",
      "Organization: Temple University\n",
      "Lines: 31\n",
      "Nntp-Posting-Host: vm.temple.edu\n",
      "X-Newsreader: NNR/VM S_1.3.2\n",
      "\n",
      "In article <cjkC5sy5G.Ko4@netcom.com>\n",
      "cjk@netcom.com writes:\n",
      " \n",
      ">This was obviously a lot different than the ordinary FBI adventure.\n",
      ">\n",
      ">I believe that the Federal officers had a conflict of interests here.\n",
      ">\n",
      ">Throught out the whole affair, it seamed to me that they were chiefly\n",
      ">concerned with saving face rather than saving lifes.  Its true that\n",
      ">The BD were resisting arrest and that they should have surrendered\n",
      ">when they first realized that these where federal officers.  But they\n",
      ">didn`t.\n",
      " \n",
      "I'm not sure what you mean by 'saving face' unless you are confusing\n",
      "the FBI with the BATF who are the ones who were in charge of the\n",
      "original search warrant.\n",
      " \n",
      ">But when they didn`t, the FBI should not have treated as a hostage\n",
      ">situation, it wasn't.\n",
      ">\n",
      ">I think  more discussions, possible independant negotiators, and\n",
      ">family intervention should have been used.\n",
      ">\n",
      "Independant Negotiators? What was there to negotiate? Any sort of plea\n",
      "bargin has to be brought to the court, the negotiators can't negotiate\n",
      "charges or sentences. FBI negotitators did make a deal for the\n",
      "Dividians to come out. Koresh showed he was not negotiating in good\n",
      "faith and there is no reason to believe independent negotiators\n",
      "would have done any better.\n",
      " \n",
      "Richard\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Revision de datos\n",
    "print(X_train[400])\n",
    "print(y_train[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizacion por medio de CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "      max_df = 0.5,            # Los tokens con proporción de aparición mayor que 'max_df' son ignorados.\n",
    "      analyzer = 'word',       # Los tokens corresponderán a palabras (este es el valor por defecto).\n",
    "      ngram_range = (1, 1),    # Limite inferior e superior de tokens por n-grama.\n",
    "      max_features = 5000      # Tamaño máximo del vocabulario.\n",
    ")\n",
    "vector_text = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño: (857, 5000)\n",
      "Tipo: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Diccionario: 5000 Terminos\n",
      "  (0, 2766)\t3\n",
      "  (0, 1167)\t2\n",
      "  (0, 4654)\t2\n",
      "  (0, 854)\t1\n",
      "  (0, 4912)\t2\n",
      "  (0, 2879)\t1\n",
      "  (0, 51)\t1\n",
      "  (0, 591)\t1\n",
      "  (0, 3896)\t1\n",
      "  (0, 2005)\t1\n",
      "  (0, 491)\t1\n",
      "  (0, 1076)\t4\n",
      "  (0, 782)\t1\n",
      "  (0, 1663)\t3\n",
      "  (0, 3571)\t1\n",
      "  (0, 2572)\t3\n",
      "  (0, 1103)\t1\n",
      "  (0, 4496)\t2\n",
      "  (0, 1265)\t1\n",
      "  (0, 1424)\t2\n",
      "  (0, 4906)\t1\n",
      "  (0, 3138)\t1\n",
      "  (0, 1271)\t1\n",
      "  (0, 3695)\t1\n",
      "  (0, 4479)\t2\n",
      "  (0, 1311)\t1\n",
      "  (0, 4860)\t1\n",
      "  (0, 4760)\t1\n",
      "  (0, 955)\t1\n",
      "  (0, 4187)\t1\n",
      "  (0, 4886)\t1\n",
      "  (0, 1736)\t1\n",
      "  (0, 1722)\t2\n",
      "  (0, 1314)\t2\n",
      "  (0, 2863)\t1\n",
      "  (0, 3143)\t1\n",
      "  (0, 3780)\t1\n",
      "  (0, 3318)\t3\n",
      "  (0, 1974)\t2\n",
      "  (0, 3092)\t1\n",
      "  (0, 4301)\t1\n",
      "  (0, 928)\t1\n",
      "  (0, 4173)\t1\n",
      "  (0, 4980)\t1\n",
      "  (0, 718)\t1\n",
      "  (0, 3472)\t1\n",
      "  (0, 4495)\t1\n",
      "  (0, 4562)\t1\n",
      "  (0, 2783)\t1\n",
      "  (0, 2711)\t1\n"
     ]
    }
   ],
   "source": [
    "#revision preliminar transformacion por CountVectorizer\n",
    "print(f\"Tamaño: {vector_text.shape}\\nTipo: {type(vector_text)}\\nDiccionario: {len(vectorizer.vocabulary_)} Terminos\")\n",
    "print(vector_text[0])\n",
    "#print(vectorizer.get_feature_names()) #Vector con features luego de tokenizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El token \"mangoe\" aparece 3 veces.\n",
      "El token \"cs\" aparece 2 veces.\n",
      "El token \"umd\" aparece 2 veces.\n",
      "El token \"charley\" aparece 1 vez.\n",
      "El token \"wingate\" aparece 2 veces.\n",
      "El token \"metaphysics\" aparece 1 vez.\n",
      "El token \"24\" aparece 1 vez.\n",
      "El token \"benedikt\" aparece 1 vez.\n",
      "El token \"rosenau\" aparece 1 vez.\n",
      "El token \"great\" aparece 1 vez.\n",
      "El token \"authority\" aparece 1 vez.\n",
      "El token \"contradictory\" aparece 4 veces.\n",
      "El token \"cannot\" aparece 1 vez.\n",
      "El token \"exist\" aparece 3 veces.\n",
      "El token \"property\" aparece 1 vez.\n",
      "El token \"language\" aparece 3 veces.\n",
      "El token \"correct\" aparece 1 vez.\n",
      "El token \"things\" aparece 2 veces.\n",
      "El token \"defined\" aparece 1 vez.\n",
      "El token \"do\" aparece 2 veces.\n",
      "El token \"will\" aparece 1 vez.\n",
      "El token \"object\" aparece 1 vez.\n",
      "El token \"definitions\" aparece 1 vez.\n",
      "El token \"reality\" aparece 1 vez.\n",
      "El token \"then\" aparece 2 veces.\n",
      "El token \"described\" aparece 1 vez.\n",
      "El token \"we\" aparece 1 vez.\n",
      "El token \"ve\" aparece 1 vez.\n",
      "El token \"come\" aparece 1 vez.\n",
      "El token \"something\" aparece 1 vez.\n",
      "El token \"which\" aparece 1 vez.\n",
      "El token \"false\" aparece 1 vez.\n",
      "El token \"failures\" aparece 2 veces.\n",
      "El token \"description\" aparece 2 veces.\n",
      "El token \"merely\" aparece 1 vez.\n",
      "El token \"objectivist\" aparece 1 vez.\n",
      "El token \"remember\" aparece 1 vez.\n",
      "El token \"peace\" aparece 3 veces.\n",
      "El token \"god\" aparece 2 veces.\n",
      "El token \"no\" aparece 1 vez.\n",
      "El token \"strife\" aparece 1 vez.\n",
      "El token \"closed\" aparece 1 vez.\n",
      "El token \"sod\" aparece 1 vez.\n",
      "El token \"yet\" aparece 1 vez.\n",
      "El token \"brothers\" aparece 1 vez.\n",
      "El token \"pray\" aparece 1 vez.\n",
      "El token \"thing\" aparece 1 vez.\n",
      "El token \"tove\" aparece 1 vez.\n",
      "El token \"marv\" aparece 1 vez.\n",
      "El token \"lous\" aparece 1 vez.\n"
     ]
    }
   ],
   "source": [
    "#Features para elemento vector_text[0]\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for ind in vector_text[0].indices:  \n",
    "    print(f'El token \"{feature_names[ind]}\" aparece {vector_text[0, ind]} {\"vez\" if vector_text[0, ind]==1 else \"veces\"}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El token \"yet\" tiene un valor de tf-idf de: 0.066565.\n",
      "El token \"wingate\" tiene un valor de tf-idf de: 0.192767.\n",
      "El token \"will\" tiene un valor de tf-idf de: 0.046972.\n",
      "El token \"which\" tiene un valor de tf-idf de: 0.044033.\n",
      "El token \"we\" tiene un valor de tf-idf de: 0.040011.\n",
      "El token \"ve\" tiene un valor de tf-idf de: 0.060770.\n",
      "El token \"umd\" tiene un valor de tf-idf de: 0.181395.\n",
      "El token \"tove\" tiene un valor de tf-idf de: 0.117556.\n",
      "El token \"things\" tiene un valor de tf-idf de: 0.118716.\n",
      "El token \"thing\" tiene un valor de tf-idf de: 0.061815.\n",
      "El token \"then\" tiene un valor de tf-idf de: 0.093011.\n",
      "El token \"strife\" tiene un valor de tf-idf de: 0.114117.\n",
      "El token \"something\" tiene un valor de tf-idf de: 0.056534.\n",
      "El token \"sod\" tiene un valor de tf-idf de: 0.117556.\n",
      "El token \"rosenau\" tiene un valor de tf-idf de: 0.089084.\n",
      "El token \"remember\" tiene un valor de tf-idf de: 0.081653.\n",
      "El token \"reality\" tiene un valor de tf-idf de: 0.091262.\n",
      "El token \"property\" tiene un valor de tf-idf de: 0.117556.\n",
      "El token \"pray\" tiene un valor de tf-idf de: 0.100307.\n",
      "El token \"peace\" tiene un valor de tf-idf de: 0.281029.\n",
      "El token \"objectivist\" tiene un valor de tf-idf de: 0.126601.\n",
      "El token \"object\" tiene un valor de tf-idf de: 0.105072.\n",
      "El token \"no\" tiene un valor de tf-idf de: 0.039897.\n",
      "El token \"metaphysics\" tiene un valor de tf-idf de: 0.123973.\n",
      "El token \"merely\" tiene un valor de tf-idf de: 0.090698.\n",
      "El token \"marv\" tiene un valor de tf-idf de: 0.117556.\n",
      "El token \"mangoe\" tiene un valor de tf-idf de: 0.295963.\n",
      "El token \"lous\" tiene un valor de tf-idf de: 0.117556.\n",
      "El token \"language\" tiene un valor de tf-idf de: 0.284967.\n",
      "El token \"great\" tiene un valor de tf-idf de: 0.072857.\n",
      "El token \"god\" tiene un valor de tf-idf de: 0.089322.\n",
      "El token \"false\" tiene un valor de tf-idf de: 0.084420.\n",
      "El token \"failures\" tiene un valor de tf-idf de: 0.266037.\n",
      "El token \"exist\" tiene un valor de tf-idf de: 0.224874.\n",
      "El token \"do\" tiene un valor de tf-idf de: 0.075645.\n",
      "El token \"description\" tiene un valor de tf-idf de: 0.206085.\n",
      "El token \"described\" tiene un valor de tf-idf de: 0.099466.\n",
      "El token \"definitions\" tiene un valor de tf-idf de: 0.106160.\n",
      "El token \"defined\" tiene un valor de tf-idf de: 0.089084.\n",
      "El token \"cs\" tiene un valor de tf-idf de: 0.131278.\n",
      "El token \"correct\" tiene un valor de tf-idf de: 0.083594.\n",
      "El token \"contradictory\" tiene un valor de tf-idf de: 0.408372.\n",
      "El token \"come\" tiene un valor de tf-idf de: 0.064750.\n",
      "El token \"closed\" tiene un valor de tf-idf de: 0.101182.\n",
      "El token \"charley\" tiene un valor de tf-idf de: 0.096384.\n",
      "El token \"cannot\" tiene un valor de tf-idf de: 0.066755.\n",
      "El token \"brothers\" tiene un valor de tf-idf de: 0.102093.\n",
      "El token \"benedikt\" tiene un valor de tf-idf de: 0.087580.\n",
      "El token \"authority\" tiene un valor de tf-idf de: 0.086170.\n",
      "El token \"24\" tiene un valor de tf-idf de: 0.086170.\n"
     ]
    }
   ],
   "source": [
    "#Analisis de frecuencias Tf-Idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(use_idf=True)\n",
    "transformed_text = transformer.fit_transform(vector_text)\n",
    "\n",
    "for ind in transformed_text[0].indices:  \n",
    "    print(f'El token \"{feature_names[ind]}\" tiene un valor de tf-idf de: {transformed_text[0, ind]:5f}.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set transformado: (857, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Set transformado: {transformed_text.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=0.5, n_estimators=50)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(    \n",
    "        n_estimators = 50,    # Número de árboles de decisión del árbol.\n",
    "        max_features =  0.5   # Proporción máxima de características a considerar.\n",
    ")\n",
    "\n",
    "clf.fit(transformed_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline de ejecucion de todo el flujo de trabajo:\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"countVectorizer\", CountVectorizer()),\n",
    "                           (\"tfidf\", TfidfTransformer()),\n",
    "                           (\"clfRandomForest\", RandomForestClassifier())])\n",
    "\n",
    "parameters = {      \n",
    "    'countVectorizer__max_features': (1000, 2000),      # Tamaño máximo del vocabulario (1000 y 2000).\n",
    "    'countVectorizer__ngram_range': ((1, 1), (1, 2)),   # Unigramas y unigramas + bigramas.\n",
    "    'tfidf__use_idf': (True, False),         # Usar o no frecuencia inversa del documento.\n",
    "    'clfRandomForest__n_estimators': [50, 100],          # Número de árboles del Random Forest (50 y 100).\n",
    "    'clfRandomForest__max_features': [0.1, 0.3]          # Porcentaje de características del Random Forest (10% y 30%).\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,   # En este caso el modelo entregado a GridSearch es un objeto PipeLine.\n",
    "                           parameters,\n",
    "                           scoring=\"f1\",\n",
    "                           cv=3)\n",
    "                                       # de ejecución y evaluación en cada entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('countVectorizer', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clfRandomForest',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'clfRandomForest__max_features': [0.1, 0.3],\n",
       "                         'clfRandomForest__n_estimators': [50, 100],\n",
       "                         'countVectorizer__max_features': (1000, 2000),\n",
       "                         'countVectorizer__ngram_range': ((1, 1), (1, 2)),\n",
       "                         'tfidf__use_idf': (True, False)},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ejecucion de GridSearch con pipeline\n",
    "\n",
    "grid_search.fit(text_data.data, text_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clfRandomForest__max_features</th>\n",
       "      <th>param_clfRandomForest__n_estimators</th>\n",
       "      <th>param_countVectorizer__max_features</th>\n",
       "      <th>param_countVectorizer__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.1, 'clfRan...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clfRandomForest__max_features': 0.3, 'clfRan...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_clfRandomForest__max_features param_clfRandomForest__n_estimators  \\\n",
       "12                                 0.1                                 100   \n",
       "15                                 0.1                                 100   \n",
       "20                                 0.3                                  50   \n",
       "13                                 0.1                                 100   \n",
       "6                                  0.1                                  50   \n",
       "14                                 0.1                                 100   \n",
       "5                                  0.1                                  50   \n",
       "9                                  0.1                                 100   \n",
       "8                                  0.1                                 100   \n",
       "28                                 0.3                                 100   \n",
       "29                                 0.3                                 100   \n",
       "4                                  0.1                                  50   \n",
       "7                                  0.1                                  50   \n",
       "23                                 0.3                                  50   \n",
       "24                                 0.3                                 100   \n",
       "21                                 0.3                                  50   \n",
       "0                                  0.1                                  50   \n",
       "16                                 0.3                                  50   \n",
       "25                                 0.3                                 100   \n",
       "31                                 0.3                                 100   \n",
       "30                                 0.3                                 100   \n",
       "22                                 0.3                                  50   \n",
       "17                                 0.3                                  50   \n",
       "1                                  0.1                                  50   \n",
       "3                                  0.1                                  50   \n",
       "11                                 0.1                                 100   \n",
       "10                                 0.1                                 100   \n",
       "26                                 0.3                                 100   \n",
       "27                                 0.3                                 100   \n",
       "18                                 0.3                                  50   \n",
       "2                                  0.1                                  50   \n",
       "19                                 0.3                                  50   \n",
       "\n",
       "   param_countVectorizer__max_features param_countVectorizer__ngram_range  \\\n",
       "12                                2000                             (1, 1)   \n",
       "15                                2000                             (1, 2)   \n",
       "20                                2000                             (1, 1)   \n",
       "13                                2000                             (1, 1)   \n",
       "6                                 2000                             (1, 2)   \n",
       "14                                2000                             (1, 2)   \n",
       "5                                 2000                             (1, 1)   \n",
       "9                                 1000                             (1, 1)   \n",
       "8                                 1000                             (1, 1)   \n",
       "28                                2000                             (1, 1)   \n",
       "29                                2000                             (1, 1)   \n",
       "4                                 2000                             (1, 1)   \n",
       "7                                 2000                             (1, 2)   \n",
       "23                                2000                             (1, 2)   \n",
       "24                                1000                             (1, 1)   \n",
       "21                                2000                             (1, 1)   \n",
       "0                                 1000                             (1, 1)   \n",
       "16                                1000                             (1, 1)   \n",
       "25                                1000                             (1, 1)   \n",
       "31                                2000                             (1, 2)   \n",
       "30                                2000                             (1, 2)   \n",
       "22                                2000                             (1, 2)   \n",
       "17                                1000                             (1, 1)   \n",
       "1                                 1000                             (1, 1)   \n",
       "3                                 1000                             (1, 2)   \n",
       "11                                1000                             (1, 2)   \n",
       "10                                1000                             (1, 2)   \n",
       "26                                1000                             (1, 2)   \n",
       "27                                1000                             (1, 2)   \n",
       "18                                1000                             (1, 2)   \n",
       "2                                 1000                             (1, 2)   \n",
       "19                                1000                             (1, 2)   \n",
       "\n",
       "   param_tfidf__use_idf                                             params  \\\n",
       "12                 True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "15                False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "20                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "13                False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "6                  True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "14                 True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "5                 False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "9                 False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "8                  True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "28                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "29                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "4                  True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "7                 False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "23                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "24                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "21                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "0                  True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "16                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "25                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "31                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "30                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "22                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "17                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "1                 False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "3                 False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "11                False  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "10                 True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "26                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "27                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "18                 True  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "2                  True  {'clfRandomForest__max_features': 0.1, 'clfRan...   \n",
       "19                False  {'clfRandomForest__max_features': 0.3, 'clfRan...   \n",
       "\n",
       "    rank_test_score  \n",
       "12                1  \n",
       "15                2  \n",
       "20                3  \n",
       "13                4  \n",
       "6                 5  \n",
       "14                6  \n",
       "5                 7  \n",
       "9                 8  \n",
       "8                 9  \n",
       "28               10  \n",
       "29               11  \n",
       "4                12  \n",
       "7                13  \n",
       "23               14  \n",
       "24               15  \n",
       "21               16  \n",
       "0                17  \n",
       "16               18  \n",
       "25               19  \n",
       "31               20  \n",
       "30               21  \n",
       "22               22  \n",
       "17               23  \n",
       "1                24  \n",
       "3                25  \n",
       "11               26  \n",
       "10               27  \n",
       "26               28  \n",
       "27               29  \n",
       "18               30  \n",
       "2                31  \n",
       "19               32  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "filter_col = [col for col in df if col.startswith('param')]\n",
    "filter_col.append(\"rank_test_score\")\n",
    "df[filter_col].sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('countVectorizer', CountVectorizer(max_features=2000)),\n",
      "                ('tfidf', TfidfTransformer()),\n",
      "                ('clfRandomForest', RandomForestClassifier(max_features=0.1))])\n",
      "Score: 0.9084688963311415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clfRandomForest__max_features': 0.1,\n",
       " 'clfRandomForest__n_estimators': 100,\n",
       " 'countVectorizer__max_features': 2000,\n",
       " 'countVectorizer__ngram_range': (1, 1),\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(f\"Score: {grid_search.best_score_}\")\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor puntaje (Train): 0.908\n"
     ]
    }
   ],
   "source": [
    "pred = grid_search.predict(X_test)\n",
    "print(f\"Mejor puntaje (Train): {grid_search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor puntaje (Test): 0.793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, pred), columns=[\"a\",\"b\"], index=[\"a\",\"b\"])\n",
    "print(f\"Mejor puntaje (Test): {grid_search.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_20_news.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
